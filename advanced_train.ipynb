{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtX7MC0ubh8kg5gsx6ezNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryfb/Batch_Image_Classification/blob/master/advanced_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoiJY38YZ0dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "804381b8-9b54-4cd7-fa09-624441a21375"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  9 14:15:03 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DssQ2JMqbZiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "1ac24856-4886-427b-c258-6f3f15f6a9b0"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpK6eu1ZL35y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "de967669-67c9-4161-e36e-f95a3e3247f9"
      },
      "source": [
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.5\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8MB 26kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchvision/\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.6\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "1.5.0+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG2lDLZra2Wq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b12152a0-9810-4065-f03c-dad9e342bf41"
      },
      "source": [
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Collecting detectron2==0.1.3\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 996kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/fvcore/\u001b[0m\n",
            "Collecting fvcore>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/69/f0/dfee20a11c469e43061532e6e1467b9f3614dab10ad5a964e14f78f6631a/fvcore-0.1.1.post20200704.tar.gz\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.18.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.3) (5.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.6.0.post3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.6.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1.post20200704-cp36-none-any.whl size=41894 sha256=4c6231398f15510c21d762609b9499c12bdb46601baa84e94aa2da36c049f992\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/d2/8e/b6d0f19811e77dabff1ebed6605ce2b59ee9f487079b434c8c\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, fvcore, mock, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.1.post20200704 mock-4.0.2 portalocker-1.7.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOyMPBJrsqwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "3a1dd71d-aac1-4390-d68e-1888e9e3f6c1"
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 18.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 18.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5rTgBClrnje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "import os\n",
        "os.environ['WANDB_API_KEY'] = '2000a87a07a37c799c731975686e15079a8c188d'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02yNu2Fahkto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6aadd756-4c69-49e1-f547-89c7619066a3"
      },
      "source": [
        "%cd drive/My\\ Drive/Project/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyQvhnIa7Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "# from detectron2.utils.logger import setup_logger\n",
        "# setup_logger()\n",
        "\n",
        "# Import common libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Import detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer  # Look into moving to a custom training loop to add weights & biases\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.config import get_cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOVifnng2-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TOGGLE PROGRAM FUNCTIONALITY\n",
        "TEST_INPUT = False  # Toggles image read test\n",
        "CONFIG = \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\" # Pre-trained model path\n",
        "TRAINING_CURVES = False  # Toggles Tensorboard training curves\n",
        "EVALUATION = False  # Toggles model evaluation\n",
        "WANDB_PROJ = 'cereal_trials'\n",
        "\n",
        "# PROGRAM CONSTANTS\n",
        "\n",
        "\n",
        "# FILE PATHS\n",
        "\n",
        "\n",
        "# TRAINING PARAMETERS\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-cRWPOyeaWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some constants\n",
        "ROOT_DIR = \"custom\"\n",
        "\n",
        "TRAIN_DATASET_NAME = ROOT_DIR + \"_train\"\n",
        "TRAIN_ANNOTATIONS = ROOT_DIR + \"/train/annotations.json\"\n",
        "TRAIN_DIR = ROOT_DIR + \"/train\"\n",
        "\n",
        "VAL_DATASET_NAME = ROOT_DIR + \"_val\"\n",
        "VAL_ANNOTATIONS = ROOT_DIR + \"/val/annotations.json\"\n",
        "VAL_DIR = ROOT_DIR + \"/val\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrmeoAawbTbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eea75c30-ebb0-4d40-a160-be5d62e5a7fb"
      },
      "source": [
        "try:\n",
        "  register_coco_instances(TRAIN_DATASET_NAME, {}, TRAIN_ANNOTATIONS, TRAIN_DIR)\n",
        "  register_coco_instances(VAL_DATASET_NAME, {}, VAL_ANNOTATIONS, VAL_DIR)\n",
        "except (AssertionError):\n",
        "  print('Dataset has aready been registered!')\n",
        "\n",
        "train_metadata = MetadataCatalog.get(TRAIN_DATASET_NAME)\n",
        "dataset_dicts = DatasetCatalog.get(TRAIN_DATASET_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26pSZM1Af1EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if TEST_INPUT:\n",
        "  for d in random.sample(dataset_dicts, 3):\n",
        "      img = cv2.imread(d[\"file_name\"])\n",
        "      visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "      out = visualizer.draw_dataset_dict(d)\n",
        "      cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABvMGt82q_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from shutil import copyfile\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "from detectron2.engine import default_argument_parser, default_setup, launch\n",
        "from detectron2.evaluation import (\n",
        "    # CityscapesInstanceEvaluator,\n",
        "    # CityscapesSemSegEvaluator,\n",
        "    COCOEvaluator,\n",
        "    COCOPanopticEvaluator,\n",
        "    DatasetEvaluators,\n",
        "    # LVISEvaluator,\n",
        "    # PascalVOCDetectionEvaluator,\n",
        "    SemSegEvaluator,\n",
        "    inference_on_dataset,\n",
        "    print_csv_format,\n",
        ")\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
        "from detectron2.utils.events import (\n",
        "    CommonMetricPrinter,\n",
        "    EventStorage,\n",
        "    JSONWriter,\n",
        "    TensorboardXWriter,\n",
        ")\n",
        "\n",
        "# Setup logger\n",
        "logger = logging.getLogger(\"detectron2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cBPAMR25GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_evaluator(cfg, dataset_name, output_folder=None):\n",
        "    \"\"\"\n",
        "    Create evaluator(s) for a given dataset.\n",
        "    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
        "    For your own dataset, you can simply create an evaluator manually in your\n",
        "    script and do not have to worry about the hacky if-else logic here.\n",
        "\n",
        "    # TODO: Edit docstring\n",
        "\n",
        "    \"\"\"\n",
        "    if output_folder is None:\n",
        "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "    evaluator_list = []\n",
        "\n",
        "    evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
        "    if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(\n",
        "            SemSegEvaluator(\n",
        "                dataset_name,\n",
        "                distributed=True,\n",
        "                num_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES,\n",
        "                ignore_label=cfg.MODEL.SEM_SEG_HEAD.IGNORE_VALUE,\n",
        "                output_dir=output_folder,\n",
        "            )\n",
        "        )\n",
        "    if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(COCOEvaluator(dataset_name, cfg, True, output_folder))\n",
        "    if evaluator_type == \"coco_panoptic_seg\":\n",
        "        evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n",
        "    # if evaluator_type == \"cityscapes_instance\":\n",
        "    #     assert (\n",
        "    #         torch.cuda.device_count() >= comm.get_rank()\n",
        "    #     ), \"CityscapesEvaluator currently do not work with multiple machines.\"\n",
        "    #     return CityscapesInstanceEvaluator(dataset_name)\n",
        "    # if evaluator_type == \"cityscapes_sem_seg\":\n",
        "    #     assert (\n",
        "    #         torch.cuda.device_count() >= comm.get_rank()\n",
        "    #     ), \"CityscapesEvaluator currently do not work with multiple machines.\"\n",
        "    #     return CityscapesSemSegEvaluator(dataset_name)\n",
        "    # if evaluator_type == \"pascal_voc\":\n",
        "    #     return PascalVOCDetectionEvaluator(dataset_name)\n",
        "    # if evaluator_type == \"lvis\":\n",
        "    #     return LVISEvaluator(dataset_name, cfg, True, output_folder)\n",
        "    if len(evaluator_list) == 0:\n",
        "        raise NotImplementedError(\n",
        "            \"no Evaluator for the dataset {} with the type {}\".format(dataset_name, evaluator_type)\n",
        "        )\n",
        "    if len(evaluator_list) == 1:\n",
        "        return evaluator_list[0]\n",
        "    return DatasetEvaluators(evaluator_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj74pNfF26zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_test(cfg, model):\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Write docstring\n",
        "    \"\"\"\n",
        "    # Initialise results dictionary\n",
        "    results = OrderedDict()\n",
        "\n",
        "    # Loop through the datasets in the config file\n",
        "    for dataset_name in cfg.DATASETS.TEST:\n",
        "        data_loader = build_detection_test_loader(cfg, dataset_name)\n",
        "\n",
        "        # Generate the evaluator\n",
        "        evaluator = get_evaluator(\n",
        "            cfg,\n",
        "            dataset_name,\n",
        "            os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
        "        )\n",
        "\n",
        "        # Run inference and add to results dictionary\n",
        "        results_i = inference_on_dataset(model, data_loader, evaluator)\n",
        "        results[dataset_name] = results_i\n",
        "        \n",
        "        logger.debug('Long the eval results on Weights & Biases')\n",
        "        wandb.log(list(results_i.items())[0][1])\n",
        "\n",
        "        if comm.is_main_process():\n",
        "            logger.info(\"Evaluation results for {} in csv format:\".format(dataset_name))\n",
        "            print_csv_format(results_i)\n",
        "    if len(results) == 1:\n",
        "        results = list(results.values())[0]\n",
        "\n",
        "    print(results)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzsH_C5D2-Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_train(cfg, model, resume=False):\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Write docstring\n",
        "    \"\"\"\n",
        "    # Set the model to train\n",
        "    model.train()\n",
        "\n",
        "    # Create torch optimiser & schedulars\n",
        "    optimizer = build_optimizer(cfg, model)\n",
        "    scheduler = build_lr_scheduler(cfg, optimizer)\n",
        "\n",
        "    # Create a torch checkpointer\n",
        "    checkpointer = DetectionCheckpointer(\n",
        "        model, cfg.OUTPUT_DIR, optimizer=optimizer, scheduler=scheduler\n",
        "    )\n",
        "\n",
        "    # Create starting checkpoint i.e. pre-trained model using weights from config\n",
        "    start_iter = (\n",
        "        checkpointer.resume_or_load(cfg.MODEL.WEIGHTS, resume=resume).get(\"iteration\", -1) + 1\n",
        "    )\n",
        "\n",
        "    # Define the number of iterations\n",
        "    max_iter = cfg.SOLVER.MAX_ITER\n",
        "\n",
        "    # Create a periodic checkpointer at the configured period\n",
        "    periodic_checkpointer = PeriodicCheckpointer(\n",
        "        checkpointer, cfg.SOLVER.CHECKPOINT_PERIOD, max_iter=max_iter\n",
        "    )\n",
        "\n",
        "    # Export checkpoint data to terminal, JSON & tensorboard files\n",
        "    writers = (\n",
        "        [\n",
        "            CommonMetricPrinter(max_iter),\n",
        "            JSONWriter(os.path.join(cfg.OUTPUT_DIR, \"metrics.json\")),\n",
        "            TensorboardXWriter(cfg.OUTPUT_DIR),\n",
        "        ]\n",
        "        if comm.is_main_process()\n",
        "        else []\n",
        "    )\n",
        "\n",
        "    # Create a data loader to supply the model with training data\n",
        "    data_loader = build_detection_train_loader(cfg)\n",
        "\n",
        "    logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
        "    with EventStorage(start_iter) as storage:\n",
        "        for data, iteration in zip(data_loader, range(start_iter, max_iter)):\n",
        "            iteration = iteration + 1\n",
        "            storage.step()\n",
        "\n",
        "            loss_dict = model(data)\n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                storage.put_scalars(total_loss=losses_reduced, **loss_dict_reduced)\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            storage.put_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], smoothing_hint=False)\n",
        "            scheduler.step()\n",
        "\n",
        "            # If eval period has been set, run test at defined interval\n",
        "            if (\n",
        "                cfg.TEST.EVAL_PERIOD > 0\n",
        "                and iteration % cfg.TEST.EVAL_PERIOD == 0\n",
        "                and iteration != max_iter\n",
        "            ):\n",
        "                do_test(cfg, model)\n",
        "                comm.synchronize()\n",
        "\n",
        "            if iteration - start_iter > 5 and (iteration % 20 == 0 or iteration == max_iter):\n",
        "                logger.debug('Logging iteration and loss to Weights & Biases')\n",
        "                wandb.log({\"Iteration\": iteration})\n",
        "                wandb.log({\"Loss\": losses})\n",
        "\n",
        "                for writer in writers:\n",
        "                    writer.write()\n",
        "            periodic_checkpointer.step(iteration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTnsfBqp3Ckj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup(args):\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(args.config_file)\n",
        "    cfg.merge_from_list(args.opts)\n",
        "\n",
        "    cfg.freeze()\n",
        "\n",
        "    # Log the configuration file to OUTPUT_DIR\n",
        "    default_setup(\n",
        "        cfg, args\n",
        "    )\n",
        "\n",
        "    # Set up the weights and biases project\n",
        "    logger.debug('Initialising Weights & Biases project')\n",
        "    wandb.init(project=WANDB_PROJ, sync_tensorboard=False)\n",
        "\n",
        "    # Load the yaml file and export it to wandb\n",
        "    cfg_export = cfg.load_yaml_with_base(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"))\n",
        "    logger.debug(\"Saving cfg file to Weights & Biases\")\n",
        "    wandb.config.update(cfg_export)\n",
        "\n",
        "    return cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK8qyY0Z3Vws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(args):\n",
        "    # Initialise the configuration datastructure\n",
        "    cfg = setup(args)\n",
        "\n",
        "    # Build a model from the configuration file\n",
        "    model = build_model(cfg)\n",
        "\n",
        "    logger.info(\"Model:\\n{}\".format(model))\n",
        "\n",
        "    # If the 'eval_only' argument is present, load the last checkpoint\n",
        "    # and return the results of the test function\n",
        "    if args.eval_only:\n",
        "        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
        "            cfg.MODEL.WEIGHTS, resume=args.resume\n",
        "        )\n",
        "        return do_test(cfg, model)\n",
        "\n",
        "    # Run the training loop\n",
        "    do_train(cfg, model, resume=args.resume)\n",
        "\n",
        "    logger.debug('Saving model to Weights & Biases')\n",
        "    copyfile('custom/output/model_final.pth', wandb.run.dir + '/model_final.pth')\n",
        "\n",
        "    # Return the results of the model test function\n",
        "    return do_test(cfg, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFXyrw-FiZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up an argument string to pass into the main function\n",
        "# workers = 2\n",
        "# ims_per_batch = 2\n",
        "# lr = 0.00025\n",
        "# max_iter = 5\n",
        "# seed = 27\n",
        "# num_classes = 2\n",
        "# config = model_zoo.get_config_file(CONFIG)\n",
        "# weights = model_zoo.get_checkpoint_url(CONFIG)\n",
        "# train = TRAIN_DATASET_NAME\n",
        "# val = VAL_DATASET_NAME\n",
        "# output = ROOT_DIR + '/output'\n",
        "# eval_period = 100\n",
        "\n",
        "# arg_string = f\"--config-file {config} \\\n",
        "#               MODEL.WEIGHTS {weights} \\\n",
        "#               OUTPUT_DIR {output} \\\n",
        "#               DATASETS.TRAIN ('{train}',) \\\n",
        "#               DATASETS.TEST ('{val}',) \\\n",
        "#               DATALOADER.NUM_WORKERS {workers} \\\n",
        "#               SOLVER.IMS_PER_BATCH {ims_per_batch} \\\n",
        "#               SOLVER.BASE_LR {lr} \\\n",
        "#               SOLVER.MAX_ITER {max_iter} \\\n",
        "#               SEED {seed} \\\n",
        "#               MODEL.ROI_HEADS.NUM_CLASSES {num_classes} \\\n",
        "#               TEST.EVAL_PERIOD {eval_period}\".split()\n",
        "\n",
        "workers = 2\n",
        "ims_per_batch = 2\n",
        "lr = 0.001\n",
        "warmup_iters = 1000\n",
        "max_iter = 1500\n",
        "step_low = 1000\n",
        "step_high = 1500\n",
        "gamma = 0.05\n",
        "# seed = 27\n",
        "num_classes = 2\n",
        "config = model_zoo.get_config_file(CONFIG)\n",
        "weights = model_zoo.get_checkpoint_url(CONFIG)\n",
        "train = TRAIN_DATASET_NAME\n",
        "val = VAL_DATASET_NAME\n",
        "output = ROOT_DIR + '/output'\n",
        "eval_period = 100\n",
        "\n",
        "arg_string = f\"--config-file {config} \\\n",
        "              MODEL.WEIGHTS {weights} \\\n",
        "              OUTPUT_DIR {output} \\\n",
        "              DATASETS.TRAIN ('{train}',) \\\n",
        "              DATASETS.TEST ('{val}',) \\\n",
        "              DATALOADER.NUM_WORKERS {workers} \\\n",
        "              SOLVER.IMS_PER_BATCH {ims_per_batch} \\\n",
        "              SOLVER.BASE_LR {lr} \\\n",
        "              SOLVER.WARMUP_ITERS {warmup_iters} \\\n",
        "              SOLVER.MAX_ITER {max_iter} \\\n",
        "              SOLVER.STEPS ({step_low},{step_high}) \\\n",
        "              SOLVER.GAMMA {gamma} \\\n",
        "              MODEL.ROI_HEADS.NUM_CLASSES {num_classes} \\\n",
        "              TEST.EVAL_PERIOD {eval_period}\".split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU2n7alqHVEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  parser = default_argument_parser()\n",
        "  args = parser.parse_args(arg_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zikm-fTHRE_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cefbe3a3-3d70-40a7-cdad-bcfec00cfa4e"
      },
      "source": [
        "main(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/09 14:18:31 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[07/09 14:18:33 detectron2]: \u001b[0mEnvironment info:\n",
            "------------------------  ---------------------------------------------------------------\n",
            "sys.platform              linux\n",
            "Python                    3.6.9 (default, Apr 18 2020, 01:56:04) [GCC 8.4.0]\n",
            "numpy                     1.18.5\n",
            "detectron2                0.1.3 @/usr/local/lib/python3.6/dist-packages/detectron2\n",
            "detectron2 compiler       GCC 7.3\n",
            "detectron2 CUDA compiler  10.1\n",
            "detectron2 arch flags     sm_35, sm_37, sm_50, sm_52, sm_60, sm_61, sm_70, sm_75\n",
            "DETECTRON2_ENV_MODULE     <not set>\n",
            "PyTorch                   1.5.0+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build       False\n",
            "CUDA available            True\n",
            "GPU 0                     Tesla K80\n",
            "CUDA_HOME                 /usr/local/cuda\n",
            "NVCC                      Cuda compilation tools, release 10.1, V10.1.243\n",
            "Pillow                    7.0.0\n",
            "torchvision               0.6.0+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n",
            "fvcore                    0.1.1.post20200704\n",
            "cv2                       4.1.2\n",
            "------------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "\u001b[32m[07/09 14:18:33 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/usr/local/lib/python3.6/dist-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl', 'OUTPUT_DIR', 'custom/output', 'DATASETS.TRAIN', \"('custom_train',)\", 'DATASETS.TEST', \"('custom_val',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '2', 'SOLVER.BASE_LR', '0.001', 'SOLVER.WARMUP_ITERS', '1000', 'SOLVER.MAX_ITER', '1500', 'SOLVER.STEPS', '(1000,1500)', 'SOLVER.GAMMA', '0.05', 'MODEL.ROI_HEADS.NUM_CLASSES', '2', 'TEST.EVAL_PERIOD', '100'], resume=False)\n",
            "\u001b[32m[07/09 14:18:33 detectron2]: \u001b[0mContents of args.config_file=/usr/local/lib/python3.6/dist-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml:\n",
            "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
            "MODEL:\n",
            "  MASK_ON: True\n",
            "  WEIGHTS: \"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\"\n",
            "  PIXEL_STD: [57.375, 57.120, 58.395]\n",
            "  RESNETS:\n",
            "    STRIDE_IN_1X1: False  # this is a C2 model\n",
            "    NUM_GROUPS: 32\n",
            "    WIDTH_PER_GROUP: 8\n",
            "    DEPTH: 101\n",
            "SOLVER:\n",
            "  STEPS: (210000, 250000)\n",
            "  MAX_ITER: 270000\n",
            "\n",
            "\u001b[32m[07/09 14:18:33 detectron2]: \u001b[0mRunning with full config:\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 2\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('custom_val',)\n",
            "  TRAIN: ('custom_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [57.375, 57.12, 58.395]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 32\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: False\n",
            "    WIDTH_PER_GROUP: 8\n",
            "  RETINANET:\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n",
            "OUTPUT_DIR: custom/output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.05\n",
            "  IMS_PER_BATCH: 2\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 1500\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  STEPS: (1000, 1500)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0.0001\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n",
            "\u001b[32m[07/09 14:18:33 detectron2]: \u001b[0mFull config saved to custom/output/config.yaml\n",
            "\u001b[32m[07/09 14:18:33 d2.utils.env]: \u001b[0mUsing a generated random seed 33892902\n",
            "\u001b[32m[07/09 14:18:33 detectron2]: \u001b[0mInitialising Weights & Biases project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/harryfb/cereal_trials\" target=\"_blank\">https://app.wandb.ai/harryfb/cereal_trials</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/harryfb/cereal_trials/runs/22v3r6l5\" target=\"_blank\">https://app.wandb.ai/harryfb/cereal_trials/runs/22v3r6l5</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/09 14:18:35 detectron2]: \u001b[0mSaving cfg file to Weights & Biases\n",
            "\u001b[32m[07/09 14:18:40 detectron2]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[07/09 14:18:40 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n",
            "\u001b[32m[07/09 14:18:40 fvcore.common.file_io]: \u001b[0mDownloading https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n",
            "\u001b[32m[07/09 14:18:40 fvcore.common.download]: \u001b[0mDownloading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_2d9806.pkl: 431MB [00:38, 11.3MB/s]                           "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/09 14:19:18 fvcore.common.download]: \u001b[0mSuccessfully downloaded /root/.torch/fvcore_cache/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl. 431414189 bytes.\n",
            "\u001b[32m[07/09 14:19:18 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl cached in /root/.torch/fvcore_cache/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mUnable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mUnable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mUnable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mUnable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mUnable to load 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mUnable to load 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model!\n",
            "\u001b[32m[07/09 14:19:19 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
            "  \u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:19:20 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:19:20 d2.data.datasets.coco]: \u001b[0mLoaded 39 images in COCO format from custom/train/annotations.json\n",
            "\u001b[32m[07/09 14:19:20 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 39 images left.\n",
            "\u001b[32m[07/09 14:19:20 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
            "\u001b[36m|   category   | #instances   |  category  | #instances   |\n",
            "|:------------:|:-------------|:----------:|:-------------|\n",
            "| _background_ | 0            |   cereal   | 82           |\n",
            "|              |              |            |              |\n",
            "|    total     | 82           |            |              |\u001b[0m\n",
            "\u001b[32m[07/09 14:19:20 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:19:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:19:20 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/09 14:19:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[07/09 14:19:20 detectron2]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/09 14:20:39 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:20:39 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.842  loss_cls: 1.000  loss_box_reg: 0.173  loss_mask: 0.682  loss_rpn_cls: 0.006  loss_rpn_loc: 0.012  lr: 0.000020  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:21:52 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:21:52 d2.utils.events]: \u001b[0m eta: 1:29:02  iter: 40  total_loss: 1.477  loss_cls: 0.695  loss_box_reg: 0.130  loss_mask: 0.611  loss_rpn_cls: 0.010  loss_rpn_loc: 0.008  lr: 0.000040  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:23:01 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:23:01 d2.utils.events]: \u001b[0m eta: 1:22:01  iter: 60  total_loss: 1.021  loss_cls: 0.338  loss_box_reg: 0.136  loss_mask: 0.520  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  lr: 0.000060  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:24:13 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:24:13 d2.utils.events]: \u001b[0m eta: 1:25:26  iter: 80  total_loss: 0.923  loss_cls: 0.217  loss_box_reg: 0.199  loss_mask: 0.447  loss_rpn_cls: 0.008  loss_rpn_loc: 0.011  lr: 0.000080  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:25:25 d2.data.datasets.coco]: \u001b[0mLoading custom/val/annotations.json takes 1.19 seconds.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:25:25 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:25:25 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 14:25:25 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:25:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:25:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 14:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.8826 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 14:25:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.535757 (2.755960 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:25:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.882566 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:25:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 14:25:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 14:25:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.767\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n",
            "\u001b[32m[07/09 14:25:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 8.159 | 16.374 | 6.658  |  nan  | 3.721 | 13.042 |\n",
            "\u001b[32m[07/09 14:25:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:25:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP    |\n",
            "|:-------------|:-----|:-----------|:------|\n",
            "| _background_ | nan  | cereal     | 8.159 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.138\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 8.178 | 13.844 | 9.488  |  nan  | 3.870 | 13.680 |\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP    |\n",
            "|:-------------|:-----|:-----------|:------|\n",
            "| _background_ | nan  | cereal     | 8.178 |\n",
            "\u001b[32m[07/09 14:25:52 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 8.159485759584422, 'AP50': 16.37438467233477, 'AP75': 6.658261040396569, 'APs': nan, 'APm': 3.721122112211221, 'APl': 13.042450841337324, 'AP-_background_': nan, 'AP-cereal': 8.159485759584422}\n",
            "\u001b[32m[07/09 14:25:52 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.testing]: \u001b[0mcopypaste: 8.1595,16.3744,6.6583,nan,3.7211,13.0425\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:25:52 d2.evaluation.testing]: \u001b[0mcopypaste: 8.1783,13.8438,9.4885,nan,3.8702,13.6802\n",
            "OrderedDict([('bbox', {'AP': 8.159485759584422, 'AP50': 16.37438467233477, 'AP75': 6.658261040396569, 'APs': nan, 'APm': 3.721122112211221, 'APl': 13.042450841337324, 'AP-_background_': nan, 'AP-cereal': 8.159485759584422}), ('segm', {'AP': 8.178324860838659, 'AP50': 13.843792928924847, 'AP75': 9.48848799650411, 'APs': nan, 'APm': 3.8702263083451207, 'APl': 13.680186964284822, 'AP-_background_': nan, 'AP-cereal': 8.178324860838659})])\n",
            "\u001b[32m[07/09 14:25:52 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:25:52 d2.utils.events]: \u001b[0m eta: 1:55:15  iter: 100  total_loss: 0.784  loss_cls: 0.166  loss_box_reg: 0.174  loss_mask: 0.383  loss_rpn_cls: 0.007  loss_rpn_loc: 0.009  lr: 0.000100  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:27:06 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:27:06 d2.utils.events]: \u001b[0m eta: 1:25:30  iter: 120  total_loss: 0.722  loss_cls: 0.163  loss_box_reg: 0.217  loss_mask: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  lr: 0.000120  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:28:15 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:28:16 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 140  total_loss: 0.525  loss_cls: 0.118  loss_box_reg: 0.150  loss_mask: 0.241  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  lr: 0.000140  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:29:28 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:29:28 d2.utils.events]: \u001b[0m eta: 1:20:44  iter: 160  total_loss: 0.581  loss_cls: 0.132  loss_box_reg: 0.193  loss_mask: 0.195  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000160  max_mem: 6277M\n",
            "\u001b[32m[07/09 14:30:41 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:30:41 d2.utils.events]: \u001b[0m eta: 1:20:28  iter: 180  total_loss: 0.428  loss_cls: 0.084  loss_box_reg: 0.159  loss_mask: 0.138  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000180  max_mem: 6444M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:31:53 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:31:53 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 14:31:53 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:31:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:31:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 14:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.8666 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 14:32:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.959126 (2.659854 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:32:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.866618 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:32:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 14:32:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 23.406 | 40.257 | 27.090 |  nan  | 18.551 | 25.366 |\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 23.406 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.472 | 39.655 | 25.853 |  nan  | 19.146 | 26.959 |\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 24.472 |\n",
            "\u001b[32m[07/09 14:32:15 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 23.405641100572577, 'AP50': 40.25690193501356, 'AP75': 27.089967622841904, 'APs': nan, 'APm': 18.550801508722298, 'APl': 25.365836749723304, 'AP-_background_': nan, 'AP-cereal': 23.405641100572577}\n",
            "\u001b[32m[07/09 14:32:15 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: 23.4056,40.2569,27.0900,nan,18.5508,25.3658\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: 24.4716,39.6554,25.8529,nan,19.1462,26.9592\n",
            "OrderedDict([('bbox', {'AP': 23.405641100572577, 'AP50': 40.25690193501356, 'AP75': 27.089967622841904, 'APs': nan, 'APm': 18.550801508722298, 'APl': 25.365836749723304, 'AP-_background_': nan, 'AP-cereal': 23.405641100572577}), ('segm', {'AP': 24.471621709057636, 'AP50': 39.65540163487121, 'AP75': 25.852945074365515, 'APs': nan, 'APm': 19.146230007616147, 'APl': 26.95918705615051, 'AP-_background_': nan, 'AP-cereal': 24.471621709057636})])\n",
            "\u001b[32m[07/09 14:32:15 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:32:15 d2.utils.events]: \u001b[0m eta: 1:41:54  iter: 200  total_loss: 0.410  loss_cls: 0.084  loss_box_reg: 0.164  loss_mask: 0.125  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000200  max_mem: 6444M\n",
            "\u001b[32m[07/09 14:33:30 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:33:31 d2.utils.events]: \u001b[0m eta: 1:20:34  iter: 220  total_loss: 0.389  loss_cls: 0.080  loss_box_reg: 0.177  loss_mask: 0.113  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  lr: 0.000220  max_mem: 6444M\n",
            "\u001b[32m[07/09 14:34:39 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:34:39 d2.utils.events]: \u001b[0m eta: 1:11:38  iter: 240  total_loss: 0.280  loss_cls: 0.056  loss_box_reg: 0.112  loss_mask: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000240  max_mem: 6444M\n",
            "\u001b[32m[07/09 14:35:51 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:35:51 d2.utils.events]: \u001b[0m eta: 1:14:56  iter: 260  total_loss: 0.268  loss_cls: 0.059  loss_box_reg: 0.090  loss_mask: 0.095  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000260  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:37:00 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:37:00 d2.utils.events]: \u001b[0m eta: 1:09:58  iter: 280  total_loss: 0.202  loss_cls: 0.050  loss_box_reg: 0.068  loss_mask: 0.083  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000280  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:38:13 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:38:13 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 14:38:13 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:38:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:38:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7684 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.433494 (1.405582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.768365 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.239\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 25.679 | 40.269 | 32.906 |  nan  | 11.528 | 31.065 |\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:38:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 25.679 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 23.835 | 36.509 | 22.946 |  nan  | 11.155 | 29.988 |\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 23.835 |\n",
            "\u001b[32m[07/09 14:38:27 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 25.679132138385906, 'AP50': 40.2694035962796, 'AP75': 32.90561124009478, 'APs': nan, 'APm': 11.528052805280527, 'APl': 31.06461733010973, 'AP-_background_': nan, 'AP-cereal': 25.679132138385906}\n",
            "\u001b[32m[07/09 14:38:27 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: 25.6791,40.2694,32.9056,nan,11.5281,31.0646\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: 23.8353,36.5094,22.9460,nan,11.1546,29.9882\n",
            "OrderedDict([('bbox', {'AP': 25.679132138385906, 'AP50': 40.2694035962796, 'AP75': 32.90561124009478, 'APs': nan, 'APm': 11.528052805280527, 'APl': 31.06461733010973, 'AP-_background_': nan, 'AP-cereal': 25.679132138385906}), ('segm', {'AP': 23.835291023827622, 'AP50': 36.5093707693328, 'AP75': 22.945960045427903, 'APs': nan, 'APm': 11.154644035832156, 'APl': 29.988208279894835, 'AP-_background_': nan, 'AP-cereal': 23.835291023827622})])\n",
            "\u001b[32m[07/09 14:38:27 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:38:27 d2.utils.events]: \u001b[0m eta: 1:26:18  iter: 300  total_loss: 0.211  loss_cls: 0.037  loss_box_reg: 0.053  loss_mask: 0.078  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000300  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:39:38 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:39:38 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 320  total_loss: 0.190  loss_cls: 0.043  loss_box_reg: 0.065  loss_mask: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000320  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:40:50 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:40:50 d2.utils.events]: \u001b[0m eta: 1:09:12  iter: 340  total_loss: 0.158  loss_cls: 0.035  loss_box_reg: 0.050  loss_mask: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000340  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:42:03 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:42:04 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 360  total_loss: 0.117  loss_cls: 0.025  loss_box_reg: 0.031  loss_mask: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000360  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:43:13 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:43:13 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 380  total_loss: 0.163  loss_cls: 0.039  loss_box_reg: 0.061  loss_mask: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000380  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:44:24 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:44:24 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 14:44:24 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:44:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:44:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7383 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.161146 (1.193524 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.738316 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 29.810 | 42.911 | 36.358 |  nan  | 10.819 | 34.574 |\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:44:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 29.810 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 26.321 | 39.766 | 26.102 |  nan  | 10.827 | 31.592 |\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 26.321 |\n",
            "\u001b[32m[07/09 14:44:36 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 29.810205112021066, 'AP50': 42.91051409261325, 'AP75': 36.35823727823123, 'APs': nan, 'APm': 10.818762727336564, 'APl': 34.57389904786037, 'AP-_background_': nan, 'AP-cereal': 29.810205112021066}\n",
            "\u001b[32m[07/09 14:44:36 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: 29.8102,42.9105,36.3582,nan,10.8188,34.5739\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:44:36 d2.evaluation.testing]: \u001b[0mcopypaste: 26.3208,39.7656,26.1018,nan,10.8268,31.5916\n",
            "OrderedDict([('bbox', {'AP': 29.810205112021066, 'AP50': 42.91051409261325, 'AP75': 36.35823727823123, 'APs': nan, 'APm': 10.818762727336564, 'APl': 34.57389904786037, 'AP-_background_': nan, 'AP-cereal': 29.810205112021066}), ('segm', {'AP': 26.320764279822008, 'AP50': 39.765563145655605, 'AP75': 26.10176502299626, 'APs': nan, 'APm': 10.826774985190827, 'APl': 31.591582979919764, 'AP-_background_': nan, 'AP-cereal': 26.320764279822008})])\n",
            "\u001b[32m[07/09 14:44:36 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:44:36 d2.utils.events]: \u001b[0m eta: 1:15:27  iter: 400  total_loss: 0.123  loss_cls: 0.025  loss_box_reg: 0.036  loss_mask: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000400  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:45:46 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:45:46 d2.utils.events]: \u001b[0m eta: 1:03:16  iter: 420  total_loss: 0.143  loss_cls: 0.021  loss_box_reg: 0.028  loss_mask: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000420  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:46:59 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:46:59 d2.utils.events]: \u001b[0m eta: 1:04:53  iter: 440  total_loss: 0.129  loss_cls: 0.023  loss_box_reg: 0.034  loss_mask: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000440  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:48:12 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:48:12 d2.utils.events]: \u001b[0m eta: 1:03:16  iter: 460  total_loss: 0.133  loss_cls: 0.026  loss_box_reg: 0.035  loss_mask: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000460  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:49:22 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:49:22 d2.utils.events]: \u001b[0m eta: 0:59:11  iter: 480  total_loss: 0.115  loss_cls: 0.019  loss_box_reg: 0.024  loss_mask: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000480  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:50:32 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:50:33 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 14:50:33 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:50:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:50:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7313 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.850715 (1.141786 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.731293 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 27.068 | 39.739 | 29.697 |  nan  | 10.859 | 30.858 |\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 27.068 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.549 | 36.993 | 23.969 |  nan  | 10.676 | 28.394 |\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 24.549 |\n",
            "\u001b[32m[07/09 14:50:44 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 27.068398750953293, 'AP50': 39.73925931820798, 'AP75': 29.696647885719468, 'APs': nan, 'APm': 10.859023402340231, 'APl': 30.857693540014075, 'AP-_background_': nan, 'AP-cereal': 27.068398750953293}\n",
            "\u001b[32m[07/09 14:50:44 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.testing]: \u001b[0mcopypaste: 27.0684,39.7393,29.6966,nan,10.8590,30.8577\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:50:44 d2.evaluation.testing]: \u001b[0mcopypaste: 24.5491,36.9934,23.9692,nan,10.6762,28.3942\n",
            "OrderedDict([('bbox', {'AP': 27.068398750953293, 'AP50': 39.73925931820798, 'AP75': 29.696647885719468, 'APs': nan, 'APm': 10.859023402340231, 'APl': 30.857693540014075, 'AP-_background_': nan, 'AP-cereal': 27.068398750953293}), ('segm', {'AP': 24.54910511320112, 'AP50': 36.99339499869101, 'AP75': 23.969169239190187, 'APs': nan, 'APm': 10.676236287596373, 'APl': 28.394205649080266, 'AP-_background_': nan, 'AP-cereal': 24.54910511320112})])\n",
            "\u001b[32m[07/09 14:50:44 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:50:44 d2.utils.events]: \u001b[0m eta: 1:08:19  iter: 500  total_loss: 0.103  loss_cls: 0.018  loss_box_reg: 0.032  loss_mask: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000500  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:51:54 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:51:54 d2.utils.events]: \u001b[0m eta: 0:57:14  iter: 520  total_loss: 0.097  loss_cls: 0.019  loss_box_reg: 0.029  loss_mask: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000519  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:53:09 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:53:10 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 540  total_loss: 0.142  loss_cls: 0.025  loss_box_reg: 0.041  loss_mask: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000539  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:54:23 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:54:23 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 560  total_loss: 0.098  loss_cls: 0.016  loss_box_reg: 0.025  loss_mask: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000559  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:55:33 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:55:33 d2.utils.events]: \u001b[0m eta: 0:53:26  iter: 580  total_loss: 0.095  loss_cls: 0.016  loss_box_reg: 0.026  loss_mask: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000579  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 14:56:46 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 14:56:46 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 14:56:46 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 14:56:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 14:56:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7338 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.047490 (1.174582 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.733752 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 27.695 | 40.317 | 29.798 |  nan  | 10.944 | 31.720 |\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 27.695 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.307 | 33.896 | 24.205 |  nan  | 13.424 | 28.203 |\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 24.307 |\n",
            "\u001b[32m[07/09 14:56:57 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 27.69454845279381, 'AP50': 40.31690181540411, 'AP75': 29.79812380537212, 'APs': nan, 'APm': 10.944467243048384, 'APl': 31.720064823275063, 'AP-_background_': nan, 'AP-cereal': 27.69454845279381}\n",
            "\u001b[32m[07/09 14:56:57 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: 27.6945,40.3169,29.7981,nan,10.9445,31.7201\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 14:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: 24.3066,33.8961,24.2051,nan,13.4238,28.2027\n",
            "OrderedDict([('bbox', {'AP': 27.69454845279381, 'AP50': 40.31690181540411, 'AP75': 29.79812380537212, 'APs': nan, 'APm': 10.944467243048384, 'APl': 31.720064823275063, 'AP-_background_': nan, 'AP-cereal': 27.69454845279381}), ('segm', {'AP': 24.30659457103637, 'AP50': 33.896099148125806, 'AP75': 24.205061374812594, 'APs': nan, 'APm': 13.423770948523423, 'APl': 28.202668641845413, 'AP-_background_': nan, 'AP-cereal': 24.30659457103637})])\n",
            "\u001b[32m[07/09 14:56:57 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:56:57 d2.utils.events]: \u001b[0m eta: 1:02:59  iter: 600  total_loss: 0.098  loss_cls: 0.018  loss_box_reg: 0.024  loss_mask: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000599  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:58:10 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:58:10 d2.utils.events]: \u001b[0m eta: 0:53:40  iter: 620  total_loss: 0.102  loss_cls: 0.018  loss_box_reg: 0.025  loss_mask: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000619  max_mem: 6549M\n",
            "\u001b[32m[07/09 14:59:23 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 14:59:23 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 640  total_loss: 0.099  loss_cls: 0.015  loss_box_reg: 0.027  loss_mask: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000639  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:00:37 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:00:37 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 660  total_loss: 0.113  loss_cls: 0.016  loss_box_reg: 0.029  loss_mask: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000659  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:01:51 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:01:51 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 680  total_loss: 0.093  loss_cls: 0.016  loss_box_reg: 0.020  loss_mask: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000679  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 15:03:06 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 15:03:06 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 15:03:06 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 15:03:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 15:03:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 15:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7256 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 15:03:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.028099 (1.004683 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:03:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.725565 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:03:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 15:03:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 15:03:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 25.010 | 33.058 | 30.639 |  nan  | 3.927 | 29.532 |\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 25.010 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.207 | 28.806 | 22.385 |  nan  | 4.208 | 25.509 |\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 21.207 |\n",
            "\u001b[32m[07/09 15:03:17 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 25.010387471380962, 'AP50': 33.05796196250797, 'AP75': 30.638674203851362, 'APs': nan, 'APm': 3.927392739273927, 'APl': 29.531539309445254, 'AP-_background_': nan, 'AP-cereal': 25.010387471380962}\n",
            "\u001b[32m[07/09 15:03:17 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: 25.0104,33.0580,30.6387,nan,3.9274,29.5315\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: 21.2065,28.8057,22.3850,nan,4.2079,25.5091\n",
            "OrderedDict([('bbox', {'AP': 25.010387471380962, 'AP50': 33.05796196250797, 'AP75': 30.638674203851362, 'APs': nan, 'APm': 3.927392739273927, 'APl': 29.531539309445254, 'AP-_background_': nan, 'AP-cereal': 25.010387471380962}), ('segm', {'AP': 21.20650806315765, 'AP50': 28.805676512994538, 'AP75': 22.38498306461977, 'APs': nan, 'APm': 4.207920792079208, 'APl': 25.509097993815544, 'AP-_background_': nan, 'AP-cereal': 21.20650806315765})])\n",
            "\u001b[32m[07/09 15:03:17 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:03:17 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 700  total_loss: 0.075  loss_cls: 0.014  loss_box_reg: 0.018  loss_mask: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000699  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:04:29 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:04:29 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 720  total_loss: 0.106  loss_cls: 0.022  loss_box_reg: 0.032  loss_mask: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000719  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:05:44 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:05:44 d2.utils.events]: \u001b[0m eta: 0:47:07  iter: 740  total_loss: 0.089  loss_cls: 0.014  loss_box_reg: 0.029  loss_mask: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000739  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:06:58 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:06:58 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 760  total_loss: 0.086  loss_cls: 0.014  loss_box_reg: 0.027  loss_mask: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000759  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:08:09 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:08:10 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 780  total_loss: 0.096  loss_cls: 0.016  loss_box_reg: 0.031  loss_mask: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000779  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 15:09:22 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 15:09:22 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 15:09:23 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 15:09:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 15:09:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7308 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.337306 (1.056218 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.730803 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.238\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 28.175 | 36.932 | 32.768 |  nan  | 11.845 | 32.607 |\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 28.175 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 25.142 | 34.081 | 25.623 |  nan  | 11.249 | 29.638 |\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 25.142 |\n",
            "\u001b[32m[07/09 15:09:33 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 28.175429567913135, 'AP50': 36.932448645591684, 'AP75': 32.76783906602768, 'APs': nan, 'APm': 11.844648750589345, 'APl': 32.60659046763018, 'AP-_background_': nan, 'AP-cereal': 28.175429567913135}\n",
            "\u001b[32m[07/09 15:09:33 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.testing]: \u001b[0mcopypaste: 28.1754,36.9324,32.7678,nan,11.8446,32.6066\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:09:33 d2.evaluation.testing]: \u001b[0mcopypaste: 25.1421,34.0812,25.6230,nan,11.2492,29.6384\n",
            "OrderedDict([('bbox', {'AP': 28.175429567913135, 'AP50': 36.932448645591684, 'AP75': 32.76783906602768, 'APs': nan, 'APm': 11.844648750589345, 'APl': 32.60659046763018, 'AP-_background_': nan, 'AP-cereal': 28.175429567913135}), ('segm', {'AP': 25.14209893775321, 'AP50': 34.08123935205703, 'AP75': 25.62304808554171, 'APs': nan, 'APm': 11.249174917491752, 'APl': 29.6384308960742, 'AP-_background_': nan, 'AP-cereal': 25.14209893775321})])\n",
            "\u001b[32m[07/09 15:09:33 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:09:33 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 800  total_loss: 0.082  loss_cls: 0.016  loss_box_reg: 0.026  loss_mask: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000799  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:10:45 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:10:46 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 820  total_loss: 0.086  loss_cls: 0.013  loss_box_reg: 0.021  loss_mask: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000819  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:11:58 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:11:58 d2.utils.events]: \u001b[0m eta: 0:39:47  iter: 840  total_loss: 0.089  loss_cls: 0.015  loss_box_reg: 0.023  loss_mask: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000839  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:13:10 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:13:10 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 860  total_loss: 0.093  loss_cls: 0.015  loss_box_reg: 0.029  loss_mask: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000859  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:14:26 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:14:26 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 880  total_loss: 0.071  loss_cls: 0.010  loss_box_reg: 0.017  loss_mask: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000879  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 15:15:38 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 15:15:38 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 15:15:38 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 15:15:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 15:15:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 15:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7247 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 15:15:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.787734 (0.964622 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:15:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.724717 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:15:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 15:15:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.238\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 26.938 | 34.908 | 31.352 |  nan  | 6.737 | 32.145 |\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 26.938 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.196\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 22.300 | 29.991 | 24.015 |  nan  | 9.786 | 26.973 |\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 22.300 |\n",
            "\u001b[32m[07/09 15:15:48 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 26.938156761506388, 'AP50': 34.90800273303293, 'AP75': 31.35197704778065, 'APs': nan, 'APm': 6.73718808269336, 'APl': 32.14464979460029, 'AP-_background_': nan, 'AP-cereal': 26.938156761506388}\n",
            "\u001b[32m[07/09 15:15:48 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: 26.9382,34.9080,31.3520,nan,6.7372,32.1446\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: 22.2995,29.9906,24.0153,nan,9.7858,26.9734\n",
            "OrderedDict([('bbox', {'AP': 26.938156761506388, 'AP50': 34.90800273303293, 'AP75': 31.35197704778065, 'APs': nan, 'APm': 6.73718808269336, 'APl': 32.14464979460029, 'AP-_background_': nan, 'AP-cereal': 26.938156761506388}), ('segm', {'AP': 22.299534613905216, 'AP50': 29.990589298035804, 'AP75': 24.0153104007645, 'APs': nan, 'APm': 9.785797934632171, 'APl': 26.973353164433117, 'AP-_background_': nan, 'AP-cereal': 22.299534613905216})])\n",
            "\u001b[32m[07/09 15:15:48 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:15:48 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 900  total_loss: 0.062  loss_cls: 0.010  loss_box_reg: 0.014  loss_mask: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000899  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:17:01 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:17:02 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 920  total_loss: 0.075  loss_cls: 0.014  loss_box_reg: 0.020  loss_mask: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000919  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:18:16 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:18:16 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 940  total_loss: 0.069  loss_cls: 0.012  loss_box_reg: 0.024  loss_mask: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000939  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:19:29 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:19:29 d2.utils.events]: \u001b[0m eta: 0:33:04  iter: 960  total_loss: 0.076  loss_cls: 0.011  loss_box_reg: 0.020  loss_mask: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000959  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:20:44 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:20:45 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 980  total_loss: 0.091  loss_cls: 0.015  loss_box_reg: 0.031  loss_mask: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000979  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 15:21:56 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 15:21:56 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 15:21:56 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 15:21:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 15:21:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7291 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.133878 (1.022313 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.729075 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.767\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 31.970 | 43.150 | 37.707 |  nan  | 16.347 | 36.049 |\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 31.970 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 27.750 | 39.351 | 29.302 |  nan  | 15.470 | 31.801 |\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 27.750 |\n",
            "\u001b[32m[07/09 15:22:07 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 31.970199103847165, 'AP50': 43.15030639406309, 'AP75': 37.706575067805325, 'APs': nan, 'APm': 16.346834683468348, 'APl': 36.0490243090202, 'AP-_background_': nan, 'AP-cereal': 31.970199103847165}\n",
            "\u001b[32m[07/09 15:22:07 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: 31.9702,43.1503,37.7066,nan,16.3468,36.0490\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: 27.7502,39.3505,29.3018,nan,15.4696,31.8005\n",
            "OrderedDict([('bbox', {'AP': 31.970199103847165, 'AP50': 43.15030639406309, 'AP75': 37.706575067805325, 'APs': nan, 'APm': 16.346834683468348, 'APl': 36.0490243090202, 'AP-_background_': nan, 'AP-cereal': 31.970199103847165}), ('segm', {'AP': 27.750205729423804, 'AP50': 39.35051187479417, 'AP75': 29.301768964612585, 'APs': nan, 'APm': 15.469589816124468, 'APl': 31.800522131287835, 'AP-_background_': nan, 'AP-cereal': 27.750205729423804})])\n",
            "\u001b[32m[07/09 15:22:07 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:22:07 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 1000  total_loss: 0.071  loss_cls: 0.009  loss_box_reg: 0.020  loss_mask: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000999  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:23:22 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:23:22 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 1020  total_loss: 0.074  loss_cls: 0.011  loss_box_reg: 0.017  loss_mask: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:24:29 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:24:30 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 1040  total_loss: 0.069  loss_cls: 0.010  loss_box_reg: 0.014  loss_mask: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:25:44 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:25:45 d2.utils.events]: \u001b[0m eta: 0:27:32  iter: 1060  total_loss: 0.072  loss_cls: 0.008  loss_box_reg: 0.012  loss_mask: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:26:53 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:26:53 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 1080  total_loss: 0.057  loss_cls: 0.010  loss_box_reg: 0.013  loss_mask: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 15:28:06 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 15:28:06 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 15:28:06 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 15:28:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 15:28:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7247 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.851620 (0.975270 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.724670 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.767\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 32.292 | 43.251 | 36.472 |  nan  | 15.542 | 36.731 |\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 32.292 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.082\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 28.507 | 38.444 | 30.914 |  nan  | 18.052 | 32.625 |\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 28.507 |\n",
            "\u001b[32m[07/09 15:28:16 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 32.291572384983965, 'AP50': 43.25123944680433, 'AP75': 36.47248760223594, 'APs': nan, 'APm': 15.542491749174916, 'APl': 36.731185810437985, 'AP-_background_': nan, 'AP-cereal': 32.291572384983965}\n",
            "\u001b[32m[07/09 15:28:16 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: 32.2916,43.2512,36.4725,nan,15.5425,36.7312\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: 28.5075,38.4441,30.9139,nan,18.0519,32.6250\n",
            "OrderedDict([('bbox', {'AP': 32.291572384983965, 'AP50': 43.25123944680433, 'AP75': 36.47248760223594, 'APs': nan, 'APm': 15.542491749174916, 'APl': 36.731185810437985, 'AP-_background_': nan, 'AP-cereal': 32.291572384983965}), ('segm', {'AP': 28.507476254329276, 'AP50': 38.444076893755316, 'AP75': 30.913876780695098, 'APs': nan, 'APm': 18.051862329090053, 'APl': 32.6250320642439, 'AP-_background_': nan, 'AP-cereal': 28.507476254329276})])\n",
            "\u001b[32m[07/09 15:28:16 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:28:16 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 1100  total_loss: 0.061  loss_cls: 0.009  loss_box_reg: 0.011  loss_mask: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:29:29 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:29:29 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 1120  total_loss: 0.053  loss_cls: 0.009  loss_box_reg: 0.011  loss_mask: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:30:46 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:30:46 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 1140  total_loss: 0.083  loss_cls: 0.013  loss_box_reg: 0.022  loss_mask: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:32:01 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:32:02 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 1160  total_loss: 0.054  loss_cls: 0.011  loss_box_reg: 0.014  loss_mask: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:33:12 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:33:12 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 1180  total_loss: 0.056  loss_cls: 0.009  loss_box_reg: 0.011  loss_mask: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 15:34:24 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/09 15:34:24 d2.data.datasets.coco]: \u001b[0mLoaded 11 images in COCO format from custom/val/annotations.json\n",
            "\u001b[32m[07/09 15:34:24 d2.data.common]: \u001b[0mSerializing 11 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/09 15:34:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[07/09 15:34:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 11 images\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/11. 0.7259 s / img. ETA=0:00:00\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.818802 (0.969800 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.725921 s / img per device, on 1 devices)\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom/output/inference/custom_val/coco_instances_results.json\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.767\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 30.876 | 41.250 | 35.176 |  nan  | 13.748 | 35.114 |\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:34:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 30.876 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.082\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 27.739 | 37.530 | 30.158 |  nan  | 15.899 | 32.030 |\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | cereal     | 27.739 |\n",
            "\u001b[32m[07/09 15:34:35 detectron2]: \u001b[0mPrint out eval results\n",
            "{'AP': 30.876113433638082, 'AP50': 41.25013525108803, 'AP75': 35.17592237730335, 'APs': nan, 'APm': 13.748132708007644, 'APl': 35.11350492558767, 'AP-_background_': nan, 'AP-cereal': 30.876113433638082}\n",
            "\u001b[32m[07/09 15:34:35 detectron2]: \u001b[0mEvaluation results for custom_val in csv format:\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.testing]: \u001b[0mcopypaste: 30.8761,41.2501,35.1759,nan,13.7481,35.1135\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/09 15:34:35 d2.evaluation.testing]: \u001b[0mcopypaste: 27.7388,37.5303,30.1578,nan,15.8990,32.0304\n",
            "OrderedDict([('bbox', {'AP': 30.876113433638082, 'AP50': 41.25013525108803, 'AP75': 35.17592237730335, 'APs': nan, 'APm': 13.748132708007644, 'APl': 35.11350492558767, 'AP-_background_': nan, 'AP-cereal': 30.876113433638082}), ('segm', {'AP': 27.738820340900826, 'AP50': 37.53030672282762, 'AP75': 30.157782595930826, 'APs': nan, 'APm': 15.898981202468077, 'APl': 32.03044722710517, 'AP-_background_': nan, 'AP-cereal': 27.738820340900826})])\n",
            "\u001b[32m[07/09 15:34:35 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:34:35 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 1200  total_loss: 0.069  loss_cls: 0.012  loss_box_reg: 0.013  loss_mask: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000050  max_mem: 6549M\n",
            "\u001b[32m[07/09 15:35:45 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[07/09 15:35:46 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 1220  total_loss: 0.055  loss_cls: 0.007  loss_box_reg: 0.011  loss_mask: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000050  max_mem: 6549M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teremBzUozI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if TRAINING_CURVES:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs0qG0rppDK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if EVALUATION:\n",
        "  from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "  from detectron2.data import build_detection_test_loader\n",
        "\n",
        "  evaluator = COCOEvaluator(VAL_DATASET_NAME, cfg, False, output_dir= ROOT_DIR + \"/output/\")\n",
        "  val_loader = build_detection_test_loader(cfg, VAL_DATASET_NAME)\n",
        "  inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}